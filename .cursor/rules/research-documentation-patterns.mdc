---
description: "Documentation patterns for scientific research projects"
globs: *.md,*.tex,*.ipynb
---
# Research Documentation Patterns

This rule establishes comprehensive documentation standards for scientific computing research projects, ensuring reproducibility, clarity, and academic rigor.

## Project Documentation Structure

### 1. Research Overview Document
```markdown
# [Project Name] - Research Overview

## Executive Summary
[2-3 sentence overview of research objectives, methods, and significance]

## Research Objectives
- [ ] Primary research question
- [ ] Specific aims and hypotheses
- [ ] Expected outcomes and impact

## Methodology Overview
- [ ] Theoretical framework
- [ ] Computational approach
- [ ] Validation strategy
- [ ] Performance requirements

## Current Status
- [ ] Completed work
- [ ] Ongoing activities
- [ ] Upcoming milestones
- [ ] Known challenges

## Key Results (Preliminary)
- [ ] Major findings to date
- [ ] Validation results
- [ ] Performance benchmarks

## References and Related Work
- [ ] Key literature citations
- [ ] Related projects
- [ ] Prior art and baselines
```

### 2. Technical Documentation Template
```markdown
# Technical Documentation: [Component Name]

## Overview
[Brief description of component purpose and scope]

## Mathematical Foundation
### Governing Equations
```math
[Primary equations and relationships]
```

### Boundary Conditions
```math
[Boundary condition specifications]
```

### Initial Conditions
```math
[Initial condition definitions]
```

## Implementation Details

### Algorithm Description
1. [Step-by-step algorithm description]
2. [Complexity analysis]
3. [Memory requirements]

### Code Structure
```
project/
├── src/
│   ├── [component]/
│   │   ├── __init__.py
│   │   ├── core.py          # Main implementation
│   │   ├── utils.py         # Utility functions
│   │   └── validation.py    # Validation routines
├── tests/
│   ├── test_[component].py
│   └── fixtures/
├── docs/
│   ├── api.md
│   └── examples.md
└── examples/
    └── [component]_demo.py
```

### API Reference
```python
def primary_function(param1: Type1, param2: Type2) -> ReturnType:
    """
    Function description.

    Parameters
    ----------
    param1 : Type1
        Description of param1
    param2 : Type2
        Description of param2

    Returns
    -------
    ReturnType
        Description of return value

    Examples
    --------
    >>> result = primary_function(value1, value2)
    >>> print(result)
    """
```

## Experiment Documentation Standards

### 1. Experiment Design Template
```markdown
# Experiment: [Experiment Name]

## Hypothesis
[Clear, testable hypothesis statement]

## Experimental Setup
### Parameters
- [ ] Independent variables and ranges
- [ ] Control variables and settings
- [ ] Dependent variables and metrics
- [ ] Environmental conditions

### Test Cases
1. [Test case 1 description]
2. [Test case 2 description]
3. [Edge case description]

### Success Criteria
- [ ] Primary success metrics
- [ ] Secondary validation criteria
- [ ] Failure conditions and thresholds

## Data Collection
### Measurement Protocol
1. [Step-by-step measurement procedure]
2. [Calibration procedures]
3. [Data quality checks]

### Data Format
```json
{
    "experiment_id": "string",
    "timestamp": "ISO8601",
    "parameters": {
        "param1": "value1",
        "param2": "value2"
    },
    "measurements": {
        "metric1": "value",
        "metric2": "value"
    },
    "metadata": {
        "version": "1.0",
        "operator": "researcher_name"
    }
}
```

## Validation Documentation Patterns

### 1. Validation Report Template
```markdown
# Validation Report: [Component/Model Name]

## Validation Overview
- **Validation Date**: [Date]
- **Validator**: [Name]
- **Validation Type**: [Analytical/Experimental/Numerical]

## Validation Criteria
- [ ] Accuracy requirements (e.g., error < 1%)
- [ ] Performance requirements (e.g., runtime < 1s)
- [ ] Robustness requirements
- [ ] Scalability requirements

## Test Results

### Accuracy Validation
| Test Case | Expected | Actual | Error | Status |
|-----------|----------|--------|-------|--------|
| Case 1    | value1   | value1 | 0.1%  | ✅ PASS |
| Case 2    | value2   | value2 | 0.05% | ✅ PASS |

### Performance Validation
- **Execution Time**: 0.234s (Target: < 1.0s) ✅
- **Memory Usage**: 45.6 MB (Target: < 100 MB) ✅
- **CPU Utilization**: 23.4% (Target: < 50%) ✅

### Robustness Validation
- [ ] Edge case handling ✅
- [ ] Error recovery ✅
- [ ] Input validation ✅
- [ ] Numerical stability ✅

## Validation Summary
**Overall Status**: ✅ PASSED

**Key Findings**:
- [Positive results and achievements]
- [Areas of strength]

**Recommendations**:
- [Suggested improvements or optimizations]
- [Future validation needs]

## Validation Artifacts
- [ ] Test data files: `validation_data_20241201.zip`
- [ ] Result plots: `validation_plots_20241201.pdf`
- [ ] Performance logs: `performance_log_20241201.txt`
- [ ] Code version: `v1.2.3`
```

### 2. Benchmark Documentation
```markdown
# Performance Benchmark Report

## Benchmark Configuration
- **Hardware**: [CPU, RAM, GPU specifications]
- **Software**: [OS, compiler, library versions]
- **Test Dataset**: [Size, characteristics, source]

## Benchmark Results

### Execution Time Analysis
```python
# Performance scaling analysis
problem_sizes = [100, 1000, 10000, 100000]
execution_times = [0.001, 0.023, 0.456, 8.923]

# Fit scaling law
log_sizes = np.log(problem_sizes)
log_times = np.log(execution_times)
slope, intercept = np.polyfit(log_sizes, log_times, 1)

print(f"Scaling: O(n^{slope:.2f})")
```

### Memory Usage Patterns
- **Peak Memory**: [value] MB
- **Memory Scaling**: [pattern]
- **Memory Efficiency**: [percentage]

### CPU Utilization
- **Average CPU**: [percentage]%
- **CPU Scaling**: [pattern]
- **Parallel Efficiency**: [percentage]

## Comparative Analysis
| Implementation | Time (s) | Memory (MB) | Efficiency |
|----------------|----------|-------------|------------|
| Reference      | 1.000    | 100         | 100%       |
| Optimized      | 0.234    | 45.6        | 426%       |
| GPU Version    | 0.089    | 156         | 1124%      |

## Recommendations
- [ ] Performance optimizations identified
- [ ] Memory usage improvements suggested
- [ ] Scaling limitations noted
- [ ] Future optimization opportunities
```

## Research Notebook Standards

### 1. Jupyter Notebook Structure
```python
# Scientific Research Notebook Template
# Title: [Research Topic]
# Author: [Researcher Name]
# Date: [Date]
# Version: [Version]

# %%
# Section 1: Setup and Imports
import numpy as np
import matplotlib.pyplot as plt
from scipy import optimize, integrate
import pandas as pd

# Set random seed for reproducibility
np.random.seed(42)

# Configure plotting
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12

# %%
# Section 2: Problem Definition
"""
Research Question:
[Clear statement of research question]

Mathematical Formulation:
[Key equations and relationships]

Objectives:
1. [Objective 1]
2. [Objective 2]
3. [Objective 3]
"""

# %%
# Section 3: Theoretical Development
"""
Theoretical Framework:
[Mathematical development of theory]

Assumptions:
1. [Assumption 1]
2. [Assumption 2]

Limitations:
1. [Limitation 1]
2. [Limitation 2]
"""

# Define key equations
def constitutive_equation(shear_rate, params):
    """Herschel-Bulkley constitutive equation."""
    tau_y, K, n = params
    return tau_y + K * shear_rate**n

# %%
# Section 4: Implementation
"""
Implementation Strategy:
[Description of implementation approach]

Algorithm:
1. [Step 1]
2. [Step 2]
3. [Step 3]
"""

class ResearchModel:
    """Research model implementation."""

    def __init__(self, parameters):
        self.params = parameters
        self.history = []

    def solve(self, inputs):
        """Solve the research problem."""
        result = self._compute_solution(inputs)
        self.history.append(result)
        return result

    def _compute_solution(self, inputs):
        """Core computation method."""
        # Implementation
        return np.zeros_like(inputs)

# %%
# Section 5: Validation
"""
Validation Strategy:
[Description of validation approach]

Test Cases:
1. Analytical validation
2. Experimental validation
3. Numerical stability
"""

# Validation functions
def validate_analytical():
    """Validate against analytical solutions."""
    # Implementation
    return True

def validate_experimental(experimental_data):
    """Validate against experimental data."""
    # Implementation
    return True

# Run validation
analytical_passed = validate_analytical()
experimental_passed = validate_experimental(experimental_data)

print(f"Analytical validation: {'PASSED' if analytical_passed else 'FAILED'}")
print(f"Experimental validation: {'PASSED' if experimental_passed else 'FAILED'}")

# %%
# Section 6: Results and Analysis
"""
Results Analysis:
[Interpretation of results]

Key Findings:
1. [Finding 1]
2. [Finding 2]

Statistical Analysis:
[Statistical validation results]
"""

# Results visualization
def plot_results(results):
    """Create comprehensive results visualization."""
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    # Plot 1: Primary results
    axes[0,0].plot(results.x, results.y, 'b-', linewidth=2)
    axes[0,0].set_xlabel('X Variable')
    axes[0,0].set_ylabel('Y Variable')
    axes[0,0].set_title('Primary Results')
    axes[0,0].grid(True, alpha=0.3)

    # Plot 2: Error analysis
    axes[0,1].plot(results.x, results.error, 'r-', linewidth=2)
    axes[0,1].set_xlabel('X Variable')
    axes[0,1].set_ylabel('Error')
    axes[0,1].set_title('Error Analysis')
    axes[0,1].grid(True, alpha=0.3)

    # Plot 3: Statistical analysis
    axes[1,0].hist(results.residuals, bins=30, alpha=0.7, color='green')
    axes[1,0].set_xlabel('Residual Value')
    axes[1,0].set_ylabel('Frequency')
    axes[1,0].set_title('Residual Distribution')
    axes[1,0].grid(True, alpha=0.3)

    # Plot 4: Performance analysis
    axes[1,1].plot(results.iterations, results.convergence, 'purple', linewidth=2)
    axes[1,1].set_xlabel('Iteration')
    axes[1,1].set_ylabel('Convergence Metric')
    axes[1,1].set_title('Convergence Analysis')
    axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    return fig

# Generate results plots
results_figure = plot_results(computation_results)
plt.show()

# %%
# Section 7: Conclusions and Future Work
"""
Conclusions:
[Summary of key findings and implications]

Future Work:
1. [Future direction 1]
2. [Future direction 2]
3. [Future direction 3]

Impact:
[Potential impact and applications]
"""

# Save notebook results
notebook_results = {
    'timestamp': pd.Timestamp.now(),
    'parameters': model_params,
    'results': computation_results,
    'validation': {
        'analytical': analytical_passed,
        'experimental': experimental_passed
    },
    'conclusions': conclusions_summary
}

# Export results
with open('research_results_20241201.json', 'w') as f:
    json.dump(notebook_results, f, indent=2, default=str)

print("Research notebook completed successfully!")
print(f"Results saved to: research_results_{pd.Timestamp.now().strftime('%Y%m%d')}.json")
```

## Code Documentation Standards

### 1. Research Code Documentation
```python
"""
Scientific Computing Research Framework

This module implements advanced computational methods for scientific research,
with emphasis on mathematical rigor, numerical stability, and validation.

Research Focus:
- Rheological modeling (Herschel-Bulkley, viscoelastic)
- Consciousness framework (Ψ(x) function)
- Inverse precision analysis (0.9987 convergence)
- Performance benchmarking and validation

Implementation Standards:
- Type hints for all public functions
- Comprehensive docstrings with examples
- Unit tests with scientific validation
- Performance profiling and optimization
- Cross-platform compatibility

Author: [Researcher Name]
Institution: [Institution]
Date: [Date]
Version: [Version]
License: [License]
"""

# Research constants and parameters
RESEARCH_CONSTANTS = {
    'convergence_threshold': 0.9987,  # Precision criterion
    'max_iterations': 1000,           # Maximum solver iterations
    'tolerance': 1e-8,                # Numerical tolerance
    'confidence_level': 0.95,         # Statistical confidence
    'random_seed': 42                 # Reproducibility seed
}

class ScientificResearchFramework:
    """
    Base class for scientific computing research frameworks.

    This class provides common functionality and standards for research
    implementations, ensuring consistency, reproducibility, and quality.

    Attributes
    ----------
    config : dict
        Framework configuration parameters
    logger : logging.Logger
        Research activity logger
    profiler : PerformanceProfiler
        Performance monitoring and profiling
    validator : ResearchValidator
        Validation and quality assurance
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize research framework.

        Parameters
        ----------
        config : dict, optional
            Configuration parameters. If None, uses defaults.

        Examples
        --------
        >>> framework = ScientificResearchFramework()
        >>> custom_config = {'precision': 1e-10, 'max_iter': 2000}
        >>> framework = ScientificResearchFramework(custom_config)
        """
        self.config = config or self._default_config()
        self._validate_config()
        self._initialize_components()

        # Setup logging
        self.logger = logging.getLogger(self.__class__.__name__)
        self.logger.info(f"Initialized {self.__class__.__name__} framework")

    def _default_config(self) -> Dict[str, Any]:
        """Provide default configuration."""
        return RESEARCH_CONSTANTS.copy()

    def _validate_config(self):
        """Validate configuration parameters."""
        required_keys = ['convergence_threshold', 'max_iterations']
        for key in required_keys:
            if key not in self.config:
                raise ValueError(f"Required configuration key missing: {key}")

        # Validate value ranges
        if not 0 < self.config['convergence_threshold'] <= 1:
            raise ValueError("Convergence threshold must be in (0, 1]")

        if self.config['max_iterations'] <= 0:
            raise ValueError("Maximum iterations must be positive")

    def _initialize_components(self):
        """Initialize framework components."""
        # Component initialization logic
        pass

    def research_workflow(self, research_problem: Any) -> ResearchResult:
        """
        Execute complete research workflow.

        This method implements the standard scientific research workflow:
        1. Problem analysis and formulation
        2. Theoretical development
        3. Implementation and validation
        4. Results analysis and interpretation
        5. Documentation and reporting

        Parameters
        ----------
        research_problem : Any
            Research problem specification

        Returns
        -------
        ResearchResult
            Complete research results and documentation

        Raises
        ------
        ResearchError
            If research workflow fails
        """
        try:
            self.logger.info("Starting research workflow")

            # Phase 1: Problem Analysis
            problem_analysis = self._analyze_research_problem(research_problem)

            # Phase 2: Theoretical Development
            theory = self._develop_theory(problem_analysis)

            # Phase 3: Implementation
            implementation = self._implement_solution(theory)

            # Phase 4: Validation
            validation = self._validate_implementation(implementation)

            # Phase 5: Results Analysis
            analysis = self._analyze_results(validation)

            # Phase 6: Documentation
            documentation = self._generate_documentation(analysis)

            result = ResearchResult(
                problem=problem_analysis,
                theory=theory,
                implementation=implementation,
                validation=validation,
                analysis=analysis,
                documentation=documentation,
                metadata=self._generate_metadata()
            )

            self.logger.info("Research workflow completed successfully")
            return result

        except Exception as e:
            self.logger.error(f"Research workflow failed: {e}")
            raise ResearchError(f"Research workflow failed: {e}") from e

    def _analyze_research_problem(self, problem: Any) -> ProblemAnalysis:
        """Analyze and formulate research problem."""
        # Implementation
        pass

    def _develop_theory(self, analysis: ProblemAnalysis) -> Theory:
        """Develop theoretical framework."""
        # Implementation
        pass

    def _implement_solution(self, theory: Theory) -> Implementation:
        """Implement theoretical solution."""
        # Implementation
        pass

    def _validate_implementation(self, implementation: Implementation) -> Validation:
        """Validate implementation correctness."""
        # Implementation
        pass

    def _analyze_results(self, validation: Validation) -> Analysis:
        """Analyze validation results."""
        # Implementation
        pass

    def _generate_documentation(self, analysis: Analysis) -> Documentation:
        """Generate research documentation."""
        # Implementation
        pass

    def _generate_metadata(self) -> Dict[str, Any]:
        """Generate research metadata."""
        return {
            'framework_version': '1.0.0',
            'timestamp': datetime.now().isoformat(),
            'config': self.config,
            'platform': platform.platform(),
            'python_version': sys.version
        }

    def performance_analysis(self) -> PerformanceReport:
        """
        Generate comprehensive performance analysis.

        Returns
        -------
        PerformanceReport
            Detailed performance analysis and recommendations
        """
        # Implementation
        pass

    def reproducibility_check(self) -> ReproducibilityReport:
        """
        Check research reproducibility.

        Returns
        -------
        ReproducibilityReport
            Reproducibility assessment and recommendations
        """
        # Implementation
        pass
```

## Quality Assurance Standards

### 1. Research Quality Checklist
```markdown
# Research Quality Assurance Checklist

## Scientific Rigor
- [ ] Clear research question and objectives
- [ ] Sound theoretical foundation
- [ ] Appropriate methodology selection
- [ ] Valid experimental design
- [ ] Proper statistical analysis
- [ ] Transparent assumptions and limitations

## Technical Quality
- [ ] Correct mathematical formulations
- [ ] Robust numerical implementations
- [ ] Comprehensive error handling
- [ ] Efficient algorithms (appropriate complexity)
- [ ] Memory-efficient data structures
- [ ] Cross-platform compatibility

## Validation and Verification
- [ ] Analytical validation against known solutions
- [ ] Experimental validation with real data
- [ ] Numerical convergence verification
- [ ] Stability analysis under perturbations
- [ ] Sensitivity analysis for key parameters
- [ ] Uncertainty quantification

## Documentation and Reproducibility
- [ ] Complete code documentation
- [ ] Clear algorithm descriptions
- [ ] Reproducible experimental setup
- [ ] Version control for code and data
- [ ] Open-source license and availability
- [ ] Data and code sharing compliance

## Performance and Scalability
- [ ] Performance benchmarks established
- [ ] Memory usage optimization
- [ ] Scalability analysis completed
- [ ] Parallel processing where applicable
- [ ] Real-time capability assessment
- [ ] Resource requirement documentation
```

This documentation framework ensures that scientific computing research maintains the highest standards of academic excellence, reproducibility, and practical utility.